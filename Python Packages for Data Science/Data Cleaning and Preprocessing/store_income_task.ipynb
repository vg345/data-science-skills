{"cells":[{"cell_type":"markdown","metadata":{"id":"lqt_yzRy16Wj"},"source":["## Compulsory Task \n","\n","In this compulsory task you will clean the country column and parse the date column in the **store_income_data_task.csv** file."]},{"cell_type":"code","execution_count":1,"metadata":{"id":"vBP3WN2O16Wp"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Cullen/Frost Bankers, Inc.</td>\n","      <td>NaN</td>\n","      <td>Clothing</td>\n","      <td>$54438554.24</td>\n","      <td>4-2-2006</td>\n","      <td>United States/</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>Nordson Corporation</td>\n","      <td>NaN</td>\n","      <td>Tools</td>\n","      <td>$41744177.01</td>\n","      <td>4-1-2006</td>\n","      <td>Britain</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>Stag Industrial, Inc.</td>\n","      <td>NaN</td>\n","      <td>Beauty</td>\n","      <td>$36152340.34</td>\n","      <td>12-9-2003</td>\n","      <td>United States</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>8-5-2006</td>\n","      <td>Britain/</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Mercantile Bank Corporation</td>\n","      <td>NaN</td>\n","      <td>Baby</td>\n","      <td>$33552742.32</td>\n","      <td>21-1-1973</td>\n","      <td>United Kingdom</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id                   store_name         store_email  department  \\\n","0   1   Cullen/Frost Bankers, Inc.                 NaN    Clothing   \n","1   2          Nordson Corporation                 NaN       Tools   \n","2   3        Stag Industrial, Inc.                 NaN      Beauty   \n","3   4          FIRST REPUBLIC BANK  ecanadine3@fc2.com  Automotive   \n","4   5  Mercantile Bank Corporation                 NaN        Baby   \n","\n","         income date_measured          country  \n","0  $54438554.24      4-2-2006   United States/  \n","1  $41744177.01      4-1-2006          Britain  \n","2  $36152340.34     12-9-2003    United States  \n","3   $8928350.04      8-5-2006         Britain/  \n","4  $33552742.32     21-1-1973   United Kingdom  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# import libraries\n","import pandas as pd\n","import fuzzywuzzy as fuzzy\n","from fuzzywuzzy import process\n","\n","# Load up store_income_data.csv\n","store = pd.read_csv('store_income_data_task.csv')\n","store.head()"]},{"cell_type":"markdown","metadata":{"id":"ItqLwumA16Wr"},"source":["1. Take a look at all the unique values in the \"country\" column. Then, convert the column to lowercase and remove any trailing white spaces."]},{"cell_type":"code","execution_count":2,"metadata":{"id":"sLkzt4Hr16Wr"},"outputs":[{"name":"stdout","output_type":"stream","text":["There are 77 unique countries.\n","['United States/' 'Britain' ' United States' 'Britain/' ' United Kingdom'\n"," 'U.K.' 'SA ' 'U.K/' 'America' 'United Kingdom' nan 'united states'\n"," ' S.A.' 'England ' 'UK' 'S.A./' 'ENGLAND' 'BRITAIN' 'U.K' 'U.K '\n"," 'America/' 'SA.' 'S.A. ' 'u.k' 'uk' ' ' 'UK.' 'England/' 'england'\n"," ' Britain' 'united states of america' 'UK/' 'SA/' 'SA' 'England.'\n"," 'UNITED KINGDOM' 'America.' 'S.A..' 's.a.' ' U.K'\n"," ' United States of America' 'Britain ' 'England' ' SA'\n"," 'United States of America.' 'United States of America/' 'United States.'\n"," 's. africasouth africa' ' England' 'United Kingdom '\n"," 'United States of America ' ' UK' 'united kingdom' 'AMERICA' 'America '\n"," 'UNITED STATES OF AMERICA' ' S. AfricaSouth Africa' 'america'\n"," 'S. AFRICASOUTH AFRICA' 'Britain.' '/' 'United Kingdom.' 'United States'\n"," ' America' 'UNITED STATES' 'sa' 'United States of America' 'UK '\n"," 'United States ' 'S. AfricaSouth Africa/' 'S.A.' 'United Kingdom/'\n"," 'S. AfricaSouth Africa ' 'S. AfricaSouth Africa.' 'S. AfricaSouth Africa'\n"," '.' 'britain']\n"]},{"data":{"text/plain":["array(['united states/', 'britain', 'united states', 'britain/',\n","       'united kingdom', 'u.k.', 'sa', 'u.k/', 'america', nan, 's.a.',\n","       'england', 'uk', 's.a./', 'u.k', 'america/', 'sa.', '', 'uk.',\n","       'england/', 'united states of america', 'uk/', 'sa/', 'england.',\n","       'america.', 's.a..', 'united states of america.',\n","       'united states of america/', 'united states.',\n","       's. africasouth africa', 'britain.', '/', 'united kingdom.',\n","       's. africasouth africa/', 'united kingdom/',\n","       's. africasouth africa.', '.'], dtype=object)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["# get unique values in country\n","countries = store['country'].unique()\n","print(f\"There are {len(countries)} unique countries.\")\n","print(countries)\n","\n","# convert to lowercase\n","store['country'] = store['country'].str.lower()\n","# remove whitespace\n","store['country'] = store['country'].str.strip()\n","store['country'].unique()"]},{"cell_type":"markdown","metadata":{"id":"P6dcDc4P16Ws"},"source":["2. Note that there should only be three separate countries. Eliminate all variations, so that 'South Africa', 'United Kingdom' and 'United States' are the only three countries."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qeV3CxMR16Ws"},"outputs":[{"name":"stdout","output_type":"stream","text":["All close matches for united kingdom fixed!\n","All close matches for south africa fixed!\n","All close matches for england fixed!\n","All close matches for america fixed!\n","All close matches for united states fixed!\n","All close matches for united states of america fixed!\n","All close matches for uk fixed!\n","All close matches for britain fixed!\n","All close matches for s.a. fixed!\n","All close matches for s. africa south africa fixed!\n"]}],"source":["def replace_matching(data, column, string_to_match, min_ratio = 85):\n","    # get unique strings\n","    all_strings = data[column].unique()\n","    # find matches. used example as guide bcoz i'm still a bit confused about this.\n","    matches = fuzzy.process.extract(string_to_match, all_strings, limit=15, scorer=fuzzy.fuzz.token_sort_ratio)\n","    close_matches = [matches[0] for matches in matches if matches[1] >= min_ratio]\n","    # locate data to replace\n","    matched_rows = data[column].isin(close_matches)\n","    # replace strings\n","    data.loc[matched_rows, column] = string_to_match  \n","    print(f\"All close matches for {string_to_match} fixed!\")\n","\n","# modify all close matches to different strings.\n","replace_matching(store, 'country', 'united kingdom')\n","replace_matching(store, 'country', 'south africa')\n","replace_matching(store, 'country', 'england')\n","replace_matching(store, 'country', 'america')\n","replace_matching(store, 'country', 'united states')\n","replace_matching(store, 'country', 'united states of america')\n","replace_matching(store, 'country', 'uk')\n","replace_matching(store, 'country', 'britain')\n","replace_matching(store, 'country', 's.a.')\n","replace_matching(store, 'country', 's. africa south africa')"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/plain":["array(['united states', 'britain', 'united kingdom', 'u.k.', 'sa', 'u.k/',\n","       'america', nan, 's.a.', 'england', 'uk', 'u.k', 'sa.', '',\n","       'united states of america', 'sa/', 's. africa south africa', '/',\n","       '.'], dtype=object)"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["store['country'].unique()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['united kingdom' 'south africa' 'united states']\n"]}],"source":["# some of the entries were not resolved by fuzzy matching and had to be manually replaced e.g. 'u.k/'\n","store['country'].replace('britain', 'united kingdom', inplace = True)\n","store['country'].replace('england', 'united kingdom', inplace = True)\n","store['country'].replace('uk', 'united kingdom', inplace = True)\n","store['country'].replace('u.k.', 'united kingdom', inplace = True)\n","store['country'].replace('sa', 'south africa', inplace = True)\n","store['country'].replace('u.k/', 'united kingdom', inplace = True)\n","store['country'].replace('u.k', 'united kingdom', inplace = True)\n","store['country'].replace('america', 'united states', inplace = True)\n","store['country'].replace('s.a.', 'south africa', inplace = True)\n","store['country'].replace('united states of america', 'united states', inplace = True)\n","store['country'].replace('s. africa south africa', 'south africa', inplace = True)\n","store['country'].replace('/', 'unknown', inplace = True)\n","store['country'].replace('.', 'unknown', inplace = True)\n","store['country'].replace('', 'unknown', inplace = True)\n","store['country'].replace('sa.', 'south africa', inplace = True)\n","store['country'].replace('sa/', 'south africa', inplace = True)\n","\n","# drop null and unknown values.\n","store.dropna(axis=0, inplace=True)\n","store.drop(store[store['country'] == 'unknown'].index, inplace=True)\n","print(store['country'].unique())"]},{"cell_type":"markdown","metadata":{"id":"UJZDMTwP16Ws"},"source":["3. Create a new column called `days_ago` in the DataFrame that is a copy of the 'date_measured' column but instead it is a number that shows how many days ago it was measured from the current date. Note that the current date can be obtained using `datetime.date.today()`."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"gMJbN84P16Wt"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>store_name</th>\n","      <th>store_email</th>\n","      <th>department</th>\n","      <th>income</th>\n","      <th>date_measured</th>\n","      <th>country</th>\n","      <th>days ago</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>FIRST REPUBLIC BANK</td>\n","      <td>ecanadine3@fc2.com</td>\n","      <td>Automotive</td>\n","      <td>$8928350.04</td>\n","      <td>2006-05-08</td>\n","      <td>united kingdom</td>\n","      <td>6520 days</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>Auburn National Bancorporation, Inc.</td>\n","      <td>ccaldeyroux5@dion.ne.jp</td>\n","      <td>Grocery</td>\n","      <td>$69798987.04</td>\n","      <td>1999-09-19</td>\n","      <td>united kingdom</td>\n","      <td>8943 days</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>Interlink Electronics, Inc.</td>\n","      <td>orodenborch6@skyrock.com</td>\n","      <td>Garden</td>\n","      <td>$22521052.79</td>\n","      <td>2001-06-08</td>\n","      <td>south africa</td>\n","      <td>8315 days</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>Synopsys, Inc.</td>\n","      <td>lcancellieri9@tmall.com</td>\n","      <td>Electronics</td>\n","      <td>$44091294.62</td>\n","      <td>2006-07-11</td>\n","      <td>united kingdom</td>\n","      <td>6456 days</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>New Home Company Inc. (The)</td>\n","      <td>nhinchcliffef@whitehouse.gov</td>\n","      <td>Shoes</td>\n","      <td>$90808764.99</td>\n","      <td>1993-04-21</td>\n","      <td>united kingdom</td>\n","      <td>11285 days</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    id                            store_name                   store_email  \\\n","3    4                   FIRST REPUBLIC BANK            ecanadine3@fc2.com   \n","5    6  Auburn National Bancorporation, Inc.       ccaldeyroux5@dion.ne.jp   \n","6    7           Interlink Electronics, Inc.      orodenborch6@skyrock.com   \n","9   10                        Synopsys, Inc.       lcancellieri9@tmall.com   \n","15  16           New Home Company Inc. (The)  nhinchcliffef@whitehouse.gov   \n","\n","     department        income date_measured         country   days ago  \n","3    Automotive   $8928350.04    2006-05-08  united kingdom  6520 days  \n","5       Grocery  $69798987.04    1999-09-19  united kingdom  8943 days  \n","6        Garden  $22521052.79    2001-06-08    south africa  8315 days  \n","9   Electronics  $44091294.62    2006-07-11  united kingdom  6456 days  \n","15        Shoes  $90808764.99    1993-04-21  united kingdom 11285 days  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["# convert date measured column to datetime format\n","store['date_measured'] = pd.to_datetime(store['date_measured'], format=\"%d-%m-%Y\") \n","# do the math to calculate how long ago the entry was measured\n","days_ago = pd.to_datetime(\"now\") - store['date_measured']\n","# create a new column to store difference in days. parse it using to_timedelta just to be sure it's all in the same format\n","store['days ago'] = pd.to_timedelta(days_ago)\n","# round off because we only want an integer for days. \n","store['days ago'] = store['days ago'].round('d')\n","# see results\n","store.head()\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/plain":["id               0\n","store_name       0\n","store_email      0\n","department       0\n","income           0\n","date_measured    0\n","country          0\n","days ago         0\n","dtype: int64"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["store.isna().sum()\n","# no nan values present in dataset. "]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3.10.0 ('phd')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"},"vscode":{"interpreter":{"hash":"63d17dc58a06b6a6d4136fb13c245dafcf53668da37b1c3052c24d689135f5bb"}}},"nbformat":4,"nbformat_minor":0}
